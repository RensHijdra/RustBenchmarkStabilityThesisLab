{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm\n",
    "import scipy.stats.mstats\n",
    "%config InlineBackend.figure_formats = ['png']\n",
    "\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from data import rciw_mjhd, rmad_hd, collect_energy_data_paths, get_project_and_benchmark_from_consumption_path, \\\n",
    "    get_normalized_mj_from_file, rmad_hd, custom_mquantiles_cimh_hd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 30\n",
    "MAX_SAMPLES_PER_ITERATION = 300\n",
    "SAMPLE_STEP = 25\n",
    "SAMPLES_PER_ITERATION_RANGE = range(SAMPLE_STEP, MAX_SAMPLES_PER_ITERATION + 1, SAMPLE_STEP)\n",
    "\n",
    "THRESHOLDS = [0.5, 1, 3, 5, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = defaultdict(list)\n",
    "\n",
    "for path in collect_energy_data_paths():\n",
    "    (proj, bench) = get_project_and_benchmark_from_consumption_path(path)\n",
    "    if proj == 'tracing':\n",
    "        continue\n",
    "    benchmarks[proj + '/' + bench.replace(\"\\\\\", \"/\")].extend(get_normalized_mj_from_file(path).tolist())\n",
    "# benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_samples = max(map(len, benchmarks.values()))\n",
    "too_little_samples = [key for key, values in benchmarks.items() if len(values) != max_samples]\n",
    "consumption = pd.DataFrame({k: v for k, v in benchmarks.items() if k not in too_little_samples})\n",
    "# pd.DataFrame({'dropped': too_little_samples, 'samples': list(map(lambda id: len(benchmarks[id]), too_little_samples))})\n",
    "consumption"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sns.stripplot(consumption.T[(consumption.T.max(axis='columns') - consumption.T.min(axis='columns')) > 50][:200], size=1, jitter=False)\n",
    "# consumption.columns[(consumption.max(axis='rows') - consumption.min(axis='rows')) > 50]\n",
    "large_consumption_difference = consumption.T[\n",
    "    (consumption.T.max(axis='columns') - consumption.T.min(axis='columns')) > 50]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sns.lineplot(large_consumption_difference.T, markers=False, estimator=None, legend=False, alpha=0.3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumption # consumption in mJ per benchmark execution\n",
    "print(f\"Maximum energy consumption for a single execution within 100ms is {consumption.max().max():.5}mJ.\")\n",
    "print(\n",
    "    f\"This translates to at most {consumption.max().max() / 0.1 / 1000:.3}W. This is {'not ' if consumption.max().max() / 0.1 / 1000 > 11.65 else ''}within the limit of a single core of the tested CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actual_instr = pd.read_csv(\"instructions.csv\", sep=\";\", names=('project', 'file', 'id', 'instructions'))\n",
    "actual_instr['id'] = actual_instr['project'] + '/' + actual_instr['id'].map(lambda s: s.strip())\n",
    "actual_instr = actual_instr.drop(columns=['project', 'file']).set_index('id')\n",
    "actual_instr = actual_instr.loc[actual_instr['instructions'] > 0]\n",
    "actual_instr = actual_instr.loc[actual_instr['instructions'] < 4.2e9 / 10]\n",
    "actual_instr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_consumption = actual_instr.join(consumption.T, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=instruction_consumption['instructions'],\n",
    "                y=stats.mstats.hdmedian(instruction_consumption.drop(columns=[\"instructions\"]), axis=1))\n",
    "plt.ylabel(\"Energy (mJ)\")\n",
    "plt.xlabel(\"Executed instruction count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(actual_instr, log_scale=(10, False), legend=False)\n",
    "plt.xlabel(\"Number of executed instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2)\n",
    "# sns.histplot(consumption.to_numpy().flatten(), bins=30, log_scale=(10, False), ax=ax[0], legend=False, stat='density')\n",
    "# sns.histplot(actual_instr, bins=30, ax=ax[1], log_scale=(10, False), legend=False, stat='density')\n",
    "\n",
    "sns.kdeplot(np.ma.getdata(stats.mstats.hdmedian(instruction_consumption.drop(columns=[\"instructions\"]), axis=1), ),\n",
    "            log_scale=(10, False), ax=ax[0], legend=False)\n",
    "ax[0].set_ylim([0, 0.25])\n",
    "ax[0].set_title(\"Median_hj energy consumption (mJ) density\")\n",
    "sns.kdeplot(instruction_consumption['instructions'], ax=ax[1], log_scale=(10, False), legend=False, )\n",
    "ax[1].set_title(\"Benchmark length (# exec. instr.) density \")\n",
    "ax[1].set_ylim([0, 0.25])\n",
    "f.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "meds = np.ma.getdata(stats.mstats.hdmedian(instruction_consumption.drop(columns=[\"instructions\"]), axis=1), )\n",
    "print(np.corrcoef(meds, instruction_consumption[\"instructions\"]))\n",
    "print(stats.spearmanr(meds, instruction_consumption[\"instructions\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Spearman Correlation statistic of 0.95 shows a high correlation between the two Ordinal variables. \n",
    "The p-value of 0.0 is lower than 0.05 and we reject the null hypothesis that the data is independent from each other. Which it isn't since it is based on the same code. This shows however that median energy and benchmark length have a correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate Stability\n",
    "Define a multithreadable task that can calculate a certain statistic over a multi-index range of up to iterations and up to samples.\n",
    "\n",
    "We calculate both RCIW and RMAD, which are both defined in [data.py](./data.py).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "\n",
    "def pooled_task(stat_fn: Callable[[np.ndarray], float], bench_id: str, values: np.ndarray, iterations: int,\n",
    "                samples: int) -> Tuple[Tuple[str, int, int], float]:\n",
    "    # indices = [i % 300 < samples for i in range(300 * iterations)]\n",
    "    # creates a Basic Indexing view into values that has shape (30, -1) where -1 can be up to 300\n",
    "    try:\n",
    "        return ((bench_id, iterations, samples), stat_fn(np.array(values[:iterations, :samples].flatten())))\n",
    "    except IndexError:\n",
    "        return ((bench_id, iterations, samples), np.NaN)\n",
    "\n",
    "\n",
    "pool = ThreadPool(processes=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import mquantiles_cimj\n",
    "\n",
    "\n",
    "def calc_rciw(data):\n",
    "    # print(len(data))\n",
    "    return rciw_mjhd(data, 0.05)\n",
    "    # diff = mquantiles_cimj(data, prob=[0.5])\n",
    "\n",
    "\n",
    "try:\n",
    "    rciw_data = pickle.load(open('rciw_95.pickle', 'rb'))\n",
    "except FileNotFoundError:\n",
    "    args = []\n",
    "    for bench in consumption.columns:\n",
    "        arranged = np.array(consumption[bench]).reshape(ITERATIONS, -1)\n",
    "        for iterations in range(ITERATIONS):\n",
    "            for samples in SAMPLES_PER_ITERATION_RANGE:\n",
    "                args.append([calc_rciw, bench, arranged, iterations + 1, samples])\n",
    "\n",
    "    rciw_data = {k: v for k, v in pool.starmap(pooled_task, args)}\n",
    "    pickle.dump(rciw_data, open('rciw_95.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def med_hj(data):\n",
    "    return custom_mquantiles_cimh_hd(data, prob=[0.5])[0]\n",
    "\n",
    "\n",
    "try:\n",
    "    median_data = pickle.load(open('medians.pickle', 'rb'))\n",
    "except FileNotFoundError:\n",
    "    args = []\n",
    "    for bench in consumption.columns:\n",
    "        arranged = np.array(consumption[bench]).reshape(ITERATIONS, -1)\n",
    "        for iterations in range(ITERATIONS):\n",
    "            for samples in SAMPLES_PER_ITERATION_RANGE:\n",
    "                args.append([med_hj, bench, arranged, iterations + 1, samples])\n",
    "\n",
    "    median_data = {k: v for k, v in pool.starmap(pooled_task, args)}\n",
    "    pickle.dump(median_data, open('medians.pickle', 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rmad_data = pickle.load(open('rmad.pickle', 'rb'))\n",
    "except FileNotFoundError:\n",
    "    args = []\n",
    "    for bench in consumption.columns:\n",
    "        arranged = np.array(consumption[bench]).reshape(ITERATIONS, -1)\n",
    "        for iterations in range(ITERATIONS):\n",
    "            for samples in SAMPLES_PER_ITERATION_RANGE:\n",
    "                args.append([rmad_hd, bench, arranged, iterations + 1, samples])\n",
    "\n",
    "    rmad_data = {k: v for k, v in pool.starmap(pooled_task, args)}\n",
    "    pickle.dump(rmad_data, open('rmad.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rciw = pd.DataFrame(rciw_data)\n",
    "\n",
    "rciw = pd.DataFrame(rciw_data.values(),\n",
    "                    index=pd.MultiIndex.from_tuples(rciw_data.keys(), names=[\"bench\", \"iterations\", \"samples\"]),\n",
    "                    columns=['rciw'])\n",
    "rmad = pd.DataFrame(rmad_data.values(),\n",
    "                    index=pd.MultiIndex.from_tuples(rmad_data.keys(), names=[\"bench\", \"iterations\", \"samples\"]),\n",
    "                    columns=['rmad'])\n",
    "medians = pd.DataFrame(rmad_data.values(),\n",
    "                    index=pd.MultiIndex.from_tuples(median_data.keys(), names=[\"bench\", \"iterations\", \"samples\"]),\n",
    "                    columns=['median'])\n",
    "\n",
    "stabilities = rmad.join(rciw)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "sns.kdeplot(stabilities * 100, ax=ax, log_scale=(10, False), common_norm=True, legend=True)\n",
    "# sns.kdeplot(stabilities, x='rciw', ax=ax, log_scale=(10, False), legend=True)\n",
    "plt.xlabel(\"Stability (%)\")\n",
    "ax.legend(['rmad', 'rciw'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# iters = range(1,31)\n",
    "iters = range(5, 31, 5)\n",
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "# local = rciw.loc[(slice(None), i, slice(None))]\n",
    "\n",
    "for idx, s in enumerate(iters):\n",
    "    ax = axs.flatten()[idx]\n",
    "    sns.lineplot(medians.loc[(slice(None), s, slice(None))], x='samples', y='median', units='bench', hue='bench',\n",
    "                 legend=False, ax=ax, estimator=None)\n",
    "    ax.set_title(f\"{s} iterations\")\n",
    "    ax.set_xlabel(\"Samples per iteration\")\n",
    "    # ax.set_ylim([0, 1.5])\n",
    "plt.tight_layout()\n",
    "# plt.yscale('log')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classify stability \n",
    "For both stability measures, classify for each threshold what proportion is stable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ratio_stable(data, x, y, subplot_value):\n",
    "    return ((data * 100) < subplot_value).loc[slice(None), x, y].value_counts(normalize=True).get(True, 0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = dict()\n",
    "for idx, threshold in enumerate(THRESHOLDS):\n",
    "\n",
    "    values = []\n",
    "    for iteration in range(ITERATIONS):\n",
    "        for samples in SAMPLES_PER_ITERATION_RANGE:\n",
    "            ratio = ratio_stable(rciw, iteration + 1, samples, threshold)\n",
    "            values.append(ratio)\n",
    "    reshaped = np.array(values).reshape(ITERATIONS, len(SAMPLES_PER_ITERATION_RANGE))\n",
    "    classified[threshold] = reshaped"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classified_rmad = dict()\n",
    "for idx, threshold in enumerate(THRESHOLDS):\n",
    "\n",
    "    values = []\n",
    "    for iteration in range(ITERATIONS):\n",
    "        for samples in SAMPLES_PER_ITERATION_RANGE:\n",
    "            ratio = ratio_stable(rmad, iteration + 1, samples, threshold)\n",
    "            values.append(ratio)\n",
    "    reshaped = np.array(values).reshape(ITERATIONS, len(SAMPLES_PER_ITERATION_RANGE))\n",
    "    classified_rmad[threshold] = reshaped"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rmad_samples = rmad.reset_index()\n",
    "rmad_samples['num_samples'] = rmad_samples['iterations'] * rmad_samples['samples']\n",
    "rmad_samples = rmad_samples.sort_values(['rmad']).drop_duplicates(['bench', 'num_samples'], keep='last')\n",
    "fig = plt.figure(dpi=300, figsize=(12, 4))\n",
    "plt.xlabel(\"Total number of samples\")\n",
    "plt.ylabel(\"Proportion of stable samples\")\n",
    "for threshold in THRESHOLDS:\n",
    "    local = rmad_samples.copy(deep=True)\n",
    "    local['stable'] = local['rmad'] < (threshold / 100)\n",
    "    percentage_stable = local.set_index('bench').groupby('num_samples')['stable'].agg(\n",
    "        'mean')  # mean calculates ratio of True/(True+False)\n",
    "    line = sns.lineplot(percentage_stable, ax=fig.gca(), label=str(threshold))\n",
    "    line.get_legend().set_title(\"Threshold (%)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "normalize = matplotlib.colors.Normalize(0, 1)\n",
    "cmap = 'PiYG'\n",
    "color_scalar = matplotlib.cm.ScalarMappable(norm=normalize, cmap=cmap)\n",
    "\n",
    "\n",
    "def multi_implot(data: dict):\n",
    "    fig, axs = plt.subplots(1, len(data), figsize=(16, 10), dpi=600)\n",
    "\n",
    "    for idx, (threshold, ratio) in enumerate(data.items()):\n",
    "        ax = axs[idx]\n",
    "        ax.imshow(ratio, cmap=cmap, interpolation='none')\n",
    "        ax.set_label(\"{}%\".format(threshold))\n",
    "        ax.set_xticks(range(0, len(SAMPLES_PER_ITERATION_RANGE), 2))\n",
    "        ax.set_xticklabels(label for id, label in enumerate(SAMPLES_PER_ITERATION_RANGE) if id % 2 == 0)\n",
    "        ax.set_yticks(range(0, ITERATIONS, 5))\n",
    "        ax.set_yticklabels(range(1, ITERATIONS + 1, 5))\n",
    "        ax.set_title(f\"{threshold}%\")\n",
    "        ax.grid(False)\n",
    "    fig.colorbar(color_scalar, ax=axs, shrink=0.5)\n",
    "    axs[0].set_ylabel(\"Iterations\")\n",
    "    # fig.supxlabel(\"Samples per iteration\")\n",
    "    # fig.supylabel(\"Iterations\")\n",
    "    axs[2].set_xlabel(\"Samples per iteration\")\n",
    "\n",
    "    # return fig"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_implot(classified)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "multi_implot(classified_rmad)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_rciw = rciw.join(actual_instr, on='bench', how='inner')\n",
    "instruction_rciw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction_sample_rciw = instruction_rciw.copy(deep=True).reset_index()\n",
    "# instruction_sample_rciw['num_samples'] = instruction_sample_rciw['iterations'] * instruction_sample_rciw['samples']\n",
    "# total_samples = total_samples.sort_values(['rciw']).drop_duplicates(['bench', 'num_samples'],keep='last')# instruction_rciw = rciw.join(actual_instr, on='bench', how='inner')\n",
    "\n",
    "# sns.scatterplot(instruction_sample_rciw, x='instructions', y='rciw', hue='num_samples')\n",
    "# plt.yscale('log')\n",
    "# plt.legend(loc='upper center')\n",
    "\n",
    "# iters = range(1,31)\n",
    "iters = range(5, 31, 5)\n",
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "\n",
    "for idx, s in enumerate(iters):\n",
    "    ax = axs.flatten()[idx]\n",
    "    sns.scatterplot(instruction_rciw.loc[:, s, :], x='instructions', y='rciw', ax=ax, alpha=0.5)\n",
    "    ax.set_title(f\"{s} iterations\")\n",
    "    ax.set_ylabel(\"RCIW (%)\")\n",
    "    ax.set_xlabel(\"Instructions\")\n",
    "    # ax.set_ylim([0, 20])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = []\n",
    "for iteration in range(ITERATIONS):\n",
    "    for samples in SAMPLES_PER_ITERATION_RANGE:\n",
    "        # print()\n",
    "        selection = instruction_rciw.loc[slice(None), iteration + 1, samples]\n",
    "        # print(selection)\n",
    "        # pearson = np.corrcoef(selection['rciw'], selection['instructions'])[0][1]\n",
    "        pearson = stats.spearmanr(selection['rciw'], selection['instructions']).statistic\n",
    "        coeff.append(pearson)\n",
    "coeff = np.array(coeff).reshape(ITERATIONS, len(SAMPLES_PER_ITERATION_RANGE))\n",
    "plt.xlabel(\"Samples per iteration\")\n",
    "plt.xticks(range(0, len(SAMPLES_PER_ITERATION_RANGE), 1),\n",
    "           [label for id, label in enumerate(SAMPLES_PER_ITERATION_RANGE) if id % 1 == 0])\n",
    "plt.imshow(coeff, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n",
    "plt.yticks(range(0, ITERATIONS, 5), range(1, ITERATIONS + 1, 5))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "print(f\"min {coeff.min():.3}; med: {np.median(coeff):.3}; max: {coeff.max():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# iters = range(1,31)\n",
    "iters = range(5, 31, 5)\n",
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "# local = rciw.loc[(slice(None), i, slice(None))]\n",
    "ll = rciw.reset_index(level='samples')\n",
    "ll['rciw'] = ll['rciw'] * 100\n",
    "for idx, s in enumerate(iters):\n",
    "    ax = axs.flatten()[idx]\n",
    "    sns.lineplot(ll.loc[(slice(None), s, slice(None))], x='samples', y='rciw', units='bench', hue='bench', legend=False,\n",
    "                 ax=ax, estimator=None)\n",
    "    ax.set_title(f\"{s} iterations\")\n",
    "    ax.set_ylabel(\"RCIW (%)\")\n",
    "    ax.set_xlabel(\"Samples per iteration\")\n",
    "    ax.set_ylim([0, 20])\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rciw.reset_index()[(rciw.reset_index()['rciw'] > .10) & (rciw.reset_index()['iterations'] > 4)].groupby('bench').count()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# iters = range(1,31)\n",
    "iters = range(5, 31, 5)\n",
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "# local = rciw.loc[(slice(None), i, slice(None))]\n",
    "\n",
    "for idx, s in enumerate(iters):\n",
    "    ax = axs.flatten()[idx]\n",
    "    sns.lineplot(rmad.loc[(slice(None), s, slice(None))], x='samples', y='rmad', units='bench', hue='bench',\n",
    "                 legend=False, ax=ax, estimator=None)\n",
    "    ax.set_title(f\"{s} iterations\")\n",
    "    ax.set_xlabel(\"Samples per iteration\")\n",
    "    # ax.set_ylim([0, 1.5])\n",
    "plt.tight_layout()\n",
    "# plt.yscale('log')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# iters = range(1,31)\n",
    "import math\n",
    "\n",
    "samps = range(50, 301, 50)\n",
    "fig, axs = plt.subplots(2, math.floor(len(samps) / 2), sharex=True, sharey=True)\n",
    "# local = rciw.loc[(slice(None), i, slice(None))]\n",
    "\n",
    "for idx, s in enumerate(samps):\n",
    "    print(f\"{idx}. {s}\")\n",
    "    ax = axs.flatten()[idx]\n",
    "    sns.lineplot(rciw.loc[(slice(None), slice(None), s)], x='iterations', y='rciw', units='bench', hue='bench',\n",
    "                 legend=False, ax=ax, estimator=None)\n",
    "    ax.set_title(f\"{s} samples\")\n",
    "    ax.set_xlabel(\"Number of iterations\")\n",
    "    # ax.set_ylim([0, 1.5])\n",
    "plt.tight_layout()\n",
    "# plt.yscale('log')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ll = rciw.reset_index(level='samples')\n",
    "# ll['rciw'] = ll['rciw'] * 1000\n",
    "ll['rciw'] *= 100\n",
    "regular_medians = ll.groupby(['iterations', 'samples']).median()\n",
    "hj_medians = ll.groupby(['iterations', 'samples']).apply(lambda df: med_hj(df['rciw'])[0],\n",
    "                                                         include_groups=False).reset_index().rename(columns={0: 'rciw'})\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.lineplot(hj_medians, x='samples', y='rciw', units='iterations', hue='iterations', legend=True, palette='viridis_r',\n",
    "             estimator=None, ax=axs[0])\n",
    "sns.lineplot(hj_medians, x='iterations', y='rciw', units='samples', hue='samples', legend=True, palette='viridis_r',\n",
    "             estimator=None, ax=axs[1])\n",
    "\n",
    "axs[0].set_xlabel(\"Samples taken per iteration\")\n",
    "axs[1].set_ylabel(\"RCIW (%)\")\n",
    "axs[0].set_ylabel(\"RCIW (%)\")\n",
    "axs[1].set_xlabel(\"Number of iterations used\")\n",
    "\n",
    "\n",
    "def is_monotonic_decreasing(data) -> bool:\n",
    "    return not not (np.diff(data) < 0).all()\n",
    "\n",
    "ll\n",
    "# [is_monotonic_decreasing(group[group['iterations'] > 15]['rciw']) for  label, group in hj_medians.groupby('samples')]# ll.groupby(['iterations','samples']).median()\n",
    "# [is_monotonic_decreasing(group['rciw']) for  label, group in hj_medians.groupby('iterations')]# ll.groupby(['iterations','samples']).median()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for label, group in hj_medians.groupby('iterations'):\n",
    "    d = np.polynomial.polynomial.polyfit(x=group['samples'], y=group['rciw'], deg=5)\n",
    "    sns.lineplot(x=SAMPLES_PER_ITERATION_RANGE,\n",
    "                 y=np.polynomial.polynomial.polyval(list(SAMPLES_PER_ITERATION_RANGE), d))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def func(x, a, b, c, d):\n",
    "    return np.log((x + d) / a) / b + c\n",
    "\n",
    "\n",
    "fitting_data = hj_medians[hj_medians['iterations'] > 4]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharey=True)\n",
    "sns.lineplot(fitting_data, x='samples', y='rciw', units='iterations', hue='iterations', legend=True,\n",
    "             palette='viridis_r', estimator=None, ax=axs[1])\n",
    "\n",
    "SSSE = 0\n",
    "popts = []\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "for label, group in fitting_data.groupby('iterations'):\n",
    "    (fit, pcov, info, mesg, ier) = curve_fit(func, xdata=group['samples'], ydata=group['rciw'], full_output=True,\n",
    "                                             bounds=([0, -np.inf, -np.inf, -21], [np.inf, 0, np.inf, np.inf]))\n",
    "    sns.lineplot(x=SAMPLES_PER_ITERATION_RANGE, y=map(lambda x: func(x, *fit), SAMPLES_PER_ITERATION_RANGE), ax=axs[0],\n",
    "                 legend=False, alpha=0.3)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    # print(perr)\n",
    "    popts.append(fit)\n",
    "    SSE = np.power(info['fvec'], 2).sum()\n",
    "    SSSE += SSE\n",
    "    print(label, \",\", \",\".join(map(str, fit)))\n",
    "print(SSSE)\n",
    "\n",
    "# print(list(map(lambda x: func(x, *fit), SAMPLES_PER_ITERATION_RANGE)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for opt in np.array(popts).T:\n",
    "    sns.lineplot(x=np.arange(5,31), y=opt)\n",
    "    \n",
    "plt.legend(['a', 'b', 'c', 'd'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "popt_fit = np.polynomial.polynomial.polyfit(np.arange(5, 31), np.array(popts), deg=1).T\n",
    "print(popt_fit)\n",
    "params = ['a', 'b', 'c', 'd']\n",
    "for idx, param in enumerate(popt_fit):\n",
    "    print(f\"{params[idx]}: v = {param[1]} * iteration {param[0]:+}\")\n",
    "    print(f\"mean {params[idx]}: {(np.arange(5, 31) * param[1] + param[0]).mean()}\")\n",
    "# np.array(popts)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predictor = lambda sample, iteration: func(sample, *[1.1497813734895757,\n",
    "                                          -0.56510988553921 * iteration - 10.021575835328116,\n",
    "                                          -0.01411705944972687 * iteration +0.6352021390905219,\n",
    "                                           -19.41007111388554])\n",
    "vec_func = np.vectorize(predictor)\n",
    "f, axs = plt.subplots(5, 5, sharex=True, sharey=True, squeeze=True, figsize=(10,10))\n",
    "axs = axs.flatten()\n",
    "for i in range(5, 30):\n",
    "    sns.lineplot(x=np.arange(25, 300), y=vec_func(np.arange(25, 300), i), label='prediction', ax=axs[i-5])\n",
    "    sns.lineplot(hj_medians.iloc[hj_medians.groupby('iterations').indices.get(i)], x='samples', y='rciw', label='actual',ax=axs[i-5], )\n",
    "    axs[i-5].set_title(i)\n",
    "    # scipy.stats.linregress(hj_medians)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
